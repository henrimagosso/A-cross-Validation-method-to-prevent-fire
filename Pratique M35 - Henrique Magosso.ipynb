{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ua64yDtEVkAe"
   },
   "source": [
    "# **MÓDULO 35 - Cross Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfSU7_b9V9zs"
   },
   "source": [
    "Nesta tarefa, você trabalhará com uma base de dados que contém informações sobre variáveis ambientais coletadas para a detecção de incêndios. O objetivo é utilizar técnicas de validação cruzada (cross-validation) para avaliar a performance de um modelo de classificação na previsão da ocorrência de um incêndio com base nas variáveis fornecidas.\n",
    "\n",
    "\n",
    "Descrição da Base de Dados\n",
    "A base de dados contém as seguintes variáveis:\n",
    "\n",
    "Unnamed:0: Índice (não é uma variável útil para o modelo)\n",
    "\n",
    "UTC: Tempo em Segundos UTC\n",
    "\n",
    "Temperature[C]: Temperatura do Ar (em graus Celsius)\n",
    "\n",
    "Humidity[%]: Umidade do Ar (em porcentagem)\n",
    "\n",
    "TVOC[ppb]: Total de Compostos Orgânicos Voláteis (medido em partes por bilhão)\n",
    "\n",
    "eCO2[ppm]: Concentração equivalente de CO2 (medido em partes por milhão)\n",
    "\n",
    "Raw H2: Hidrogênio molecular bruto, não compensado\n",
    "\n",
    "Raw Ethanol: Etanol gasoso bruto\n",
    "\n",
    "Pressure[hPA]: Pressão do Ar (em hectopascais)\n",
    "\n",
    "PM1.0: Material particulado de tamanho < 1,0 µm\n",
    "\n",
    "PM2.5: Material particulado de tamanho >1,0 µm e < 2,5 µm\n",
    "\n",
    "NC0.5: Concentração numérica de material particulado de tamanho < 0,5 µm\n",
    "\n",
    "NC1.0: Concentração numérica de material particulado de tamanho 0,5 µm < 1,0 µm\n",
    "\n",
    "NC2.5: Concentração numérica de material particulado de tamanho 1,0 µm < 2,5 µm\n",
    "\n",
    "CNT: Contador de amostras\n",
    "\n",
    "\n",
    "E a variável alvo:\n",
    "\n",
    "Fire Alarm: Indicador binário de incêndio (1 se houver incêndio, 0 caso contrário)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beLG8E0gWJ3B"
   },
   "source": [
    "O objetivo desta tarefa é aplicar a técnica de validação cruzada (cross-validation) para avaliar a performance de um modelo de classificação. A validação cruzada ajudará a garantir que o modelo seja avaliado de maneira robusta e generalize bem para dados não vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "F2Re2qbeWg_S"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PavdJLwnWV0w"
   },
   "source": [
    "# 1 - Carregue a base de dados, verifique os tipos de dados e também se há presença de dados faltantes ou nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "I3zRYpX8YVic"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62630 entries, 0 to 62629\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Unnamed: 0      62630 non-null  int64  \n",
      " 1   UTC             62630 non-null  int64  \n",
      " 2   Temperature[C]  62630 non-null  float64\n",
      " 3   Humidity[%]     62630 non-null  float64\n",
      " 4   TVOC[ppb]       62630 non-null  int64  \n",
      " 5   eCO2[ppm]       62630 non-null  int64  \n",
      " 6   Raw H2          62630 non-null  int64  \n",
      " 7   Raw Ethanol     62630 non-null  int64  \n",
      " 8   Pressure[hPa]   62630 non-null  float64\n",
      " 9   PM1.0           62630 non-null  float64\n",
      " 10  PM2.5           62630 non-null  float64\n",
      " 11  NC0.5           62630 non-null  float64\n",
      " 12  NC1.0           62630 non-null  float64\n",
      " 13  NC2.5           62630 non-null  float64\n",
      " 14  CNT             62630 non-null  int64  \n",
      " 15  Fire Alarm      62630 non-null  int64  \n",
      "dtypes: float64(8), int64(8)\n",
      "memory usage: 7.6 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Cientista de dados M35 - smoke_detection_iot.csv')\n",
    "df.info()\n",
    "# Não foi detectado nenhum valor ausente. \n",
    "# Apenas as colunas TVOC, NC e PM possuem valores zero não booleanos.\n",
    "# Um TVOC = 0  presente em inúmeras linhas da coluna será mantido por didática, embora seja quase impossível obter esse valor de pureza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFCle1hkXXZJ"
   },
   "source": [
    "Para a coluna Fire Alarm, por conta do espaçamento talvez seja util renomear o nome da coluna utilizando:\n",
    "\n",
    "df.rename(columns={'Fire Alarm': 'Fire_Alarm'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Fire Alarm': 'Fire_Alarm', 'Raw H2': 'Raw_H2', 'Raw Ethanol':'Raw_Ethanol'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOD9k9LAW8Kk"
   },
   "source": [
    "# 2 - Para essa base, onde você realizará as previsões de fire alarm, qual modelo de machine learning você aplicará? Justifique.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Irei realizar dois modelos distintos para essa tarefa, deixarei documentado o modelo que tiver menor desempenho.\n",
    "# Irei testar o modelo de Regressão logística e Random Florest, se pudesse apostar minhas fichas em um deles, apostaria no Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ME4lOgO5Wx1a"
   },
   "source": [
    "# 3 - Separe a base em Y e X e já rode a instância do modelo que você utilizará."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FaI7oQazXOMU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 1.00\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3594\n",
      "           1       1.00      1.00      1.00      8932\n",
      "\n",
      "    accuracy                           1.00     12526\n",
      "   macro avg       1.00      1.00      1.00     12526\n",
      "weighted avg       1.00      1.00      1.00     12526\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[3594    0]\n",
      " [   0 8932]]\n"
     ]
    }
   ],
   "source": [
    "# 3 - Random Forest\n",
    "X = df.drop('Fire_Alarm',axis = 1)\n",
    "Y = df['Fire_Alarm']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Iniciando o modelo Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "# Treinando o modelo\n",
    "rf_model.fit(X_train, Y_train)\n",
    "# Fazendo previsões no conjunto de teste\n",
    "Y_pred = rf_model.predict(X_test)\n",
    "# Avaliando o modelo\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "report = classification_report(Y_test, Y_pred)\n",
    "conf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "\n",
    "print(f\"Acurácia: {accuracy:.2f}\")\n",
    "print(\"Relatório de Classificação:\\n\", report)\n",
    "print(\"Matriz de Confusão:\\n\", conf_matrix)\n",
    "\n",
    "# O modelo apresentou um comportamento de predição PERFEITO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resultados para Regressão Logística ---\n",
      "Acurácia: 0.97\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96      3594\n",
      "           1       0.99      0.97      0.98      8932\n",
      "\n",
      "    accuracy                           0.97     12526\n",
      "   macro avg       0.96      0.98      0.97     12526\n",
      "weighted avg       0.98      0.97      0.97     12526\n",
      "\n",
      "Matriz de Confusão:\n",
      " [[3530   64]\n",
      " [ 253 8679]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\henri\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 3 - Regressão Logística\n",
    "X \n",
    "Y \n",
    "# Separação da base em treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Iniciando o modelo de Regressão Logística\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=200)\n",
    "# Treinando o modelo\n",
    "lr_model.fit(X_train, Y_train)\n",
    "# Fazendo previsões no conjunto de teste\n",
    "Y_pred_lr = lr_model.predict(X_test)\n",
    "# Avaliando o modelo\n",
    "accuracy_lr = accuracy_score(Y_test, Y_pred_lr)\n",
    "report_lr = classification_report(Y_test, Y_pred_lr)\n",
    "conf_matrix_lr = confusion_matrix(Y_test, Y_pred_lr)\n",
    "\n",
    "print(f\"--- Resultados para Regressão Logística ---\")\n",
    "print(f\"Acurácia: {accuracy_lr:.2f}\")\n",
    "print(\"Relatório de Classificação:\\n\", report_lr)\n",
    "print(\"Matriz de Confusão:\\n\", conf_matrix_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTSxwAL-XxC_"
   },
   "source": [
    "# 4 - Defina o número de Folds e rode o modelo com a validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácias por fold na validação cruzada: [1.         0.9997605  0.99984033 1.         0.99960083]\n",
      "Acurácia média da validação cruzada: 1.00\n",
      "Desvio padrão da acurácia: 0.00\n"
     ]
    }
   ],
   "source": [
    "# 4 - Random Forest\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(rf_model, X, Y, cv=kf, scoring='accuracy')\n",
    "print(f\"Acurácias por fold na validação cruzada: {cv_scores}\")\n",
    "print(f\"Acurácia média da validação cruzada: {cv_scores.mean():.2f}\")\n",
    "print(f\"Desvio padrão da acurácia: {cv_scores.std():.2f}\")\n",
    "# O desvio padrão de zero nos confirma consistência entre os splits realizados. \n",
    "# Os resultados todos próximos de 1 confirmam a robustez e capacidade preditória do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "OyPPGETSX4Ug"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\henri\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\henri\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resultados da Validação Cruzada para Regressão Logística ---\n",
      "Acurácias por fold na validação cruzada: [0.97565065 0.97748683 0.97732716 0.97692799 0.97581031]\n",
      "Acurácia média da validação cruzada: 0.98\n",
      "Desvio padrão da acurácia: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\henri\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 4 - Regressão Logística\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Realizando a validação cruzada para o modelo de Regressão Logística\n",
    "cv_scores_lr = cross_val_score(lr_model, X, Y, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(f\"--- Resultados da Validação Cruzada para Regressão Logística ---\")\n",
    "print(f\"Acurácias por fold na validação cruzada: {cv_scores_lr}\")\n",
    "print(f\"Acurácia média da validação cruzada: {cv_scores_lr.mean():.2f}\")\n",
    "print(f\"Desvio padrão da acurácia: {cv_scores_lr.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_xggQ5DX9mL"
   },
   "source": [
    "# 5 - Avalie a pontuação de cada modelo e ao final a validação final da média."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Zdw7Rs0IYDt5"
   },
   "outputs": [],
   "source": [
    "# Com base nesses resultados, o modelo Random Forest é claramente superior para esta tarefa de detecção de incêndios no conjunto de dados.\n",
    "# Sua capacidade de atingir 100% de precisão e recall, eliminando Falsos Positivos(quando não houve incêndio mas o algoritmo disse que houve) \n",
    "# e, principalmente, Falsos Negativos(quando houve incêndio o o algoritmo não previu), o torna a escolha ideal."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
